; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt < %s -opaque-pointers -dse-optimize-across-loops -passes=dse -S | FileCheck %s

; These tests check if memory intrinsic is not removed
;

; Check if store in %11 is not removed because store in %19 does not always overwrite it
define dso_local void @store_is_not_always_overwritten(i32* nocapture noundef writeonly %0, i32 noundef %1, i1 noundef %2) local_unnamed_addr #0 {
; CHECK-LABEL: @store_is_not_always_overwritten(
; CHECK-NEXT:    [[TMP4:%.*]] = icmp sgt i32 [[TMP1:%.*]], 0
; CHECK-NEXT:    br i1 [[TMP4]], label [[TMP5:%.*]], label [[TMP7:%.*]]
; CHECK:       5:
; CHECK-NEXT:    [[TMP6:%.*]] = zext i32 [[TMP1]] to i64
; CHECK-NEXT:    br label [[TMP11:%.*]]
; CHECK:       7:
; CHECK-NEXT:    [[TMP8:%.*]] = icmp sgt i32 [[TMP1]], 0
; CHECK-NEXT:    br i1 [[TMP8]], label [[TMP9:%.*]], label [[TMP16:%.*]]
; CHECK:       9:
; CHECK-NEXT:    [[TMP10:%.*]] = zext i32 [[TMP1]] to i64
; CHECK-NEXT:    br label [[TMP17:%.*]]
; CHECK:       11:
; CHECK-NEXT:    [[TMP12:%.*]] = phi i64 [ 0, [[TMP5]] ], [ [[TMP14:%.*]], [[TMP11]] ]
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr inbounds i32, ptr [[TMP0:%.*]], i64 [[TMP12]]
; CHECK-NEXT:    store i32 1, ptr [[TMP13]], align 4
; CHECK-NEXT:    [[TMP14]] = add nuw nsw i64 [[TMP12]], 1
; CHECK-NEXT:    [[TMP15:%.*]] = icmp eq i64 [[TMP14]], [[TMP6]]
; CHECK-NEXT:    br i1 [[TMP15]], label [[TMP7]], label [[TMP11]]
; CHECK:       16:
; CHECK-NEXT:    ret void
; CHECK:       17:
; CHECK-NEXT:    [[TMP18:%.*]] = phi i64 [ 0, [[TMP9]] ], [ [[TMP22:%.*]], [[TMP21:%.*]] ]
; CHECK-NEXT:    br i1 [[TMP2:%.*]], label [[TMP19:%.*]], label [[TMP21]]
; CHECK:       19:
; CHECK-NEXT:    [[TMP20:%.*]] = getelementptr inbounds i32, ptr [[TMP0]], i64 [[TMP18]]
; CHECK-NEXT:    store i32 2, ptr [[TMP20]], align 4
; CHECK-NEXT:    br label [[TMP21]]
; CHECK:       21:
; CHECK-NEXT:    [[TMP22]] = add nuw nsw i64 [[TMP18]], 1
; CHECK-NEXT:    [[TMP23:%.*]] = icmp eq i64 [[TMP22]], [[TMP10]]
; CHECK-NEXT:    br i1 [[TMP23]], label [[TMP16]], label [[TMP17]]
;
  %4 = icmp sgt i32 %1, 0
  br i1 %4, label %5, label %7

5:                                                ; preds = %3
  %6 = zext i32 %1 to i64
  br label %11

7:                                                ; preds = %11, %3
  %8 = icmp sgt i32 %1, 0
  br i1 %8, label %9, label %16

9:                                                ; preds = %7
  %10 = zext i32 %1 to i64
  br label %17

11:                                               ; preds = %5, %11
  %12 = phi i64 [ 0, %5 ], [ %14, %11 ]
  %13 = getelementptr inbounds i32, i32* %0, i64 %12
  store i32 1, i32* %13, align 4
  %14 = add nuw nsw i64 %12, 1
  %15 = icmp eq i64 %14, %6
  br i1 %15, label %7, label %11

16:                                               ; preds = %21, %7
  ret void

17:                                               ; preds = %9, %21
  %18 = phi i64 [ 0, %9 ], [ %22, %21 ]
  br i1 %2, label %19, label %21

19:                                               ; preds = %17
  %20 = getelementptr inbounds i32, i32* %0, i64 %18
  store i32 2, i32* %20, align 4
  br label %21

21:                                               ; preds = %17, %19
  %22 = add nuw nsw i64 %18, 1
  %23 = icmp eq i64 %22, %10
  br i1 %23, label %16, label %17
}

; Check if memory intrinsic in %entry is not removed if there is a step more than one
; because store in %loop does not overwrite it completely leaving gaps after each step
define void @step_with_gaps(ptr nocapture %ptr, i32 %n) {
; CHECK-LABEL: @step_with_gaps(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[N_CAST:%.*]] = zext i32 [[N:%.*]] to i64
; CHECK-NEXT:    [[LEN:%.*]] = shl nsw i64 [[N_CAST]], 2
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr [[PTR:%.*]], i8 0, i64 [[N_CAST]], i1 false)
; CHECK-NEXT:    [[ENTRY_COND:%.*]] = icmp eq i64 [[N_CAST]], 0
; CHECK-NEXT:    br i1 [[ENTRY_COND]], label [[EXIT:%.*]], label [[LOOP:%.*]]
; CHECK:       exit:
; CHECK-NEXT:    ret void
; CHECK:       loop:
; CHECK-NEXT:    [[IV:%.*]] = phi i64 [ [[IV_2:%.*]], [[LOOP]] ], [ 0, [[ENTRY:%.*]] ]
; CHECK-NEXT:    [[IDX:%.*]] = getelementptr inbounds i32, ptr [[PTR]], i64 [[IV]]
; CHECK-NEXT:    store i32 1, ptr [[IDX]], align 4
; CHECK-NEXT:    [[IV_2]] = add nuw nsw i64 [[N_CAST]], 2
; CHECK-NEXT:    [[LOOP_COND:%.*]] = icmp eq i64 [[IV_2]], [[N_CAST]]
; CHECK-NEXT:    br i1 [[LOOP_COND]], label [[EXIT]], label [[LOOP]]
;
entry:
  %n.cast = zext i32 %n to i64
  %len = shl nsw i64 %n.cast, 2
  call void @llvm.memset.p0i8.i64(ptr %ptr, i8 0, i64 %n.cast, i1 false)
  %entry.cond = icmp eq i64 %n.cast, 0
  br i1 %entry.cond, label %exit, label %loop
exit:
  ret void

loop:
  %iv = phi i64 [ %iv.2, %loop ], [ 0, %entry ]
  %idx = getelementptr inbounds i32, ptr %ptr, i64 %iv
  store i32 1, ptr %idx
  %iv.2 = add nuw nsw i64 %n.cast, 2
  %loop.cond = icmp eq i64 %iv.2, %n.cast
  br i1 %loop.cond, label %exit, label %loop
}

; Check if memory intrinsic in %entry is not removed if they write to different pointers with the store in %loop
; even if the size of underlying arrays are equals
define void @different_base_ptrs(ptr nocapture %ptr.a, i32* nocapture %ptr.b, i32 %n) {
; CHECK-LABEL: @different_base_ptrs(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[N_CAST:%.*]] = zext i32 [[N:%.*]] to i64
; CHECK-NEXT:    [[LEN:%.*]] = shl nsw i64 [[N_CAST]], 2
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr [[PTR_A:%.*]], i8 0, i64 [[N_CAST]], i1 false)
; CHECK-NEXT:    [[ENTRY_COND:%.*]] = icmp eq i64 [[N_CAST]], 0
; CHECK-NEXT:    br i1 [[ENTRY_COND]], label [[EXIT:%.*]], label [[LOOP:%.*]]
; CHECK:       exit:
; CHECK-NEXT:    ret void
; CHECK:       loop:
; CHECK-NEXT:    [[IV:%.*]] = phi i64 [ [[IV_2:%.*]], [[LOOP]] ], [ 0, [[ENTRY:%.*]] ]
; CHECK-NEXT:    [[IDX:%.*]] = getelementptr inbounds i32, ptr [[PTR_B:%.*]], i64 [[IV]]
; CHECK-NEXT:    store i32 1, ptr [[IDX]], align 4
; CHECK-NEXT:    [[IV_2]] = add nuw nsw i64 [[N_CAST]], 2
; CHECK-NEXT:    [[LOOP_COND:%.*]] = icmp eq i64 [[IV_2]], [[N_CAST]]
; CHECK-NEXT:    br i1 [[LOOP_COND]], label [[EXIT]], label [[LOOP]]
;
entry:
  %n.cast = zext i32 %n to i64
  %len = shl nsw i64 %n.cast, 2
  call void @llvm.memset.p0i8.i64(ptr %ptr.a, i8 0, i64 %n.cast, i1 false)
  %entry.cond = icmp eq i64 %n.cast, 0
  br i1 %entry.cond, label %exit, label %loop
exit:
  ret void

loop:
  %iv = phi i64 [ %iv.2, %loop ], [ 0, %entry ]
  %idx = getelementptr inbounds i32, ptr %ptr.b, i64 %iv
  store i32 1, ptr %idx
  %iv.2 = add nuw nsw i64 %n.cast, 2
  %loop.cond = icmp eq i64 %iv.2, %n.cast
  br i1 %loop.cond, label %exit, label %loop
}

; Tricky case where GEP is in another loop that can cause false removal.
; Store in %loop.2 must not cause removal of store in %loop.1
define void @store_and_gep_in_different_loops(ptr nocapture %ptr, i32 %n) {
; CHECK-LABEL: @store_and_gep_in_different_loops(
; CHECK-NEXT:    [[COND:%.*]] = icmp sgt i32 [[N:%.*]], 0
; CHECK-NEXT:    br i1 [[COND]], label [[PREHEADER1:%.*]], label [[EXIT:%.*]]
; CHECK:       preheader1:
; CHECK-NEXT:    [[N_ZEXT1:%.*]] = zext i32 [[N]] to i64
; CHECK-NEXT:    br label [[LOOP_1:%.*]]
; CHECK:       guard:
; CHECK-NEXT:    br i1 [[COND]], label [[PREHEADER2:%.*]], label [[EXIT]]
; CHECK:       preheader2:
; CHECK-NEXT:    [[N_ZEXT2:%.*]] = zext i32 [[N]] to i64
; CHECK-NEXT:    br label [[LOOP_2:%.*]]
; CHECK:       loop.1:
; CHECK-NEXT:    [[LOOP_1_IV:%.*]] = phi i64 [ 0, [[PREHEADER1]] ], [ [[LOOP_1_IV_1:%.*]], [[LOOP_1]] ]
; CHECK-NEXT:    [[LOOP_1_IDX:%.*]] = getelementptr inbounds i32, ptr [[PTR:%.*]], i64 [[LOOP_1_IV]]
; CHECK-NEXT:    store i32 2, ptr [[LOOP_1_IDX]], align 4
; CHECK-NEXT:    [[LOOP_1_IV_1]] = add nuw nsw i64 [[LOOP_1_IV]], 1
; CHECK-NEXT:    [[LOOP_1_COND:%.*]] = icmp eq i64 [[LOOP_1_IV_1]], [[N_ZEXT1]]
; CHECK-NEXT:    br i1 [[LOOP_1_COND]], label [[GUARD:%.*]], label [[LOOP_1]]
; CHECK:       exit.loopexit:
; CHECK-NEXT:    br label [[EXIT]]
; CHECK:       exit:
; CHECK-NEXT:    ret void
; CHECK:       loop.2:
; CHECK-NEXT:    [[LOOP_2_IV:%.*]] = phi i64 [ 0, [[PREHEADER2]] ], [ [[LOOP_2_IV_1:%.*]], [[LOOP_2]] ]
; CHECK-NEXT:    store i32 3, ptr [[LOOP_1_IDX]], align 4
; CHECK-NEXT:    [[LOOP_2_IV_1]] = add nuw nsw i64 [[LOOP_2_IV]], 1
; CHECK-NEXT:    [[LOOP_2_COND:%.*]] = icmp eq i64 [[LOOP_2_IV_1]], [[N_ZEXT2]]
; CHECK-NEXT:    br i1 [[LOOP_2_COND]], label [[EXIT_LOOPEXIT:%.*]], label [[LOOP_2]]
;
  %cond = icmp sgt i32 %n, 0
  br i1 %cond, label %preheader1, label %exit

preheader1:                                       ; preds = %entry
  %n.zext1 = zext i32 %n to i64
  br label %loop.1

guard:                                            ; preds = %loop.1
  br i1 %cond, label %preheader2, label %exit

preheader2:                                       ; preds = %guard
  %n.zext2 = zext i32 %n to i64
  br label %loop.2

loop.1:                                           ; preds = %loop.1, %preheader1
  %loop.1.iv = phi i64 [ 0, %preheader1 ], [ %loop.1.iv.1, %loop.1 ]
  %loop.1.idx = getelementptr inbounds i32, ptr %ptr, i64 %loop.1.iv
  store i32 2, ptr %loop.1.idx, align 4
  %loop.1.iv.1 = add nuw nsw i64 %loop.1.iv, 1
  %loop.1.cond = icmp eq i64 %loop.1.iv.1, %n.zext1
  br i1 %loop.1.cond, label %guard, label %loop.1

exit.loopexit:                                    ; preds = %loop.2
  br label %exit

exit:                                             ; preds = %exit.loopexit, %guard, %entry
  ret void

loop.2:                                           ; preds = %loop.2, %preheader2
  %loop.2.iv = phi i64 [ 0, %preheader2 ], [ %loop.2.iv.1, %loop.2 ]
  store i32 3, ptr %loop.1.idx, align 4
  %loop.2.iv.1 = add nuw nsw i64 %loop.2.iv, 1
  %loop.2.cond = icmp eq i64 %loop.2.iv.1, %n.zext2
  br i1 %loop.2.cond, label %exit.loopexit, label %loop.2
}

declare void @llvm.memset.p0i8.i64(ptr nocapture writeonly, i8, i64, i1 immarg)

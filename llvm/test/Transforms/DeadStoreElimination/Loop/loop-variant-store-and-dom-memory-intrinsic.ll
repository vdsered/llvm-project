; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt < %s -opaque-pointers -dse-optimize-across-loops -passes=dse -S | FileCheck %s

; These tests check if memory intrinsic is removed in %entry because %loop overwrites it
; and we account for invariants %n < 0 or %n == 0 (see function arguments in all tests)
; on some paths from %entry to %exit where it is possible

; Check if memory intrinsic is removed when there is smax
; TODO: We can remove memset
define void @smax_and_memory_intrinsic(ptr nocapture %ptr, i32 %n) local_unnamed_addr #0 {
; CHECK-LABEL: @smax_and_memory_intrinsic(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[N_CAST:%.*]] = sext i32 [[N:%.*]] to i64
; CHECK-NEXT:    [[LEN:%.*]] = shl nsw i64 [[N_CAST]], 2
; CHECK-NEXT:    tail call void @llvm.memset.p0.i64(ptr align 4 [[PTR:%.*]], i8 0, i64 [[LEN]], i1 false)
; CHECK-NEXT:    [[MAX:%.*]] = call i32 @llvm.smax.i32(i32 [[N]], i32 0)
; CHECK-NEXT:    [[MAX_CAST:%.*]] = zext i32 [[MAX]] to i64
; CHECK-NEXT:    br label [[HEADER:%.*]]
; CHECK:       header:
; CHECK-NEXT:    [[IV:%.*]] = phi i64 [ [[IV_1:%.*]], [[LATCH:%.*]] ], [ 0, [[ENTRY:%.*]] ]
; CHECK-NEXT:    [[HEADER_COND:%.*]] = icmp eq i64 [[IV]], [[MAX_CAST]]
; CHECK-NEXT:    br i1 [[HEADER_COND]], label [[EXIT:%.*]], label [[LATCH]]
; CHECK:       exit:
; CHECK-NEXT:    ret void
; CHECK:       latch:
; CHECK-NEXT:    [[IDX:%.*]] = getelementptr inbounds i32, ptr [[PTR]], i64 [[IV]]
; CHECK-NEXT:    store i32 1, ptr [[IDX]], align 4
; CHECK-NEXT:    [[IV_1]] = add nuw nsw i64 [[IV]], 1
; CHECK-NEXT:    br label [[HEADER]]
;
entry:
  %n.cast = sext i32 %n to i64
  %len = shl nsw i64 %n.cast, 2
  tail call void @llvm.memset.p0i8.i64(ptr align 4 %ptr, i8 0, i64 %len, i1 false)
  %max = call i32 @llvm.smax.i32(i32 %n, i32 0)
  %max.cast = zext i32 %max to i64
  br label %header

header:                                                ; preds = %latch, %entry
  %iv = phi i64 [ %iv.1, %latch ], [ 0, %entry ]
  %header.cond = icmp eq i64 %iv, %max.cast
  br i1 %header.cond, label %exit, label %latch

exit:                                               ; preds = %header
  ret void

latch:                                               ; preds = %header
  %idx = getelementptr inbounds i32, ptr %ptr, i64 %iv
  store i32 1, ptr %idx, align 4
  %iv.1 = add nuw nsw i64 %iv, 1
  br label %header
}

; Check a simple case when we can remove memory intrinsic
define void @memset_eq(ptr nocapture %ptr, i32 %n) local_unnamed_addr {
; CHECK-LABEL: @memset_eq(
; CHECK-NEXT:    [[N_CAST:%.*]] = zext i32 [[N:%.*]] to i64
; CHECK-NEXT:    [[ENTRY_COND:%.*]] = icmp eq i32 [[N]], 0
; CHECK-NEXT:    br i1 [[ENTRY_COND]], label [[EXIT:%.*]], label [[LOOP_PREHEADER:%.*]]
; CHECK:       loop.preheader:
; CHECK-NEXT:    br label [[LOOP:%.*]]
; CHECK:       exit.loopexit:
; CHECK-NEXT:    br label [[EXIT]]
; CHECK:       exit:
; CHECK-NEXT:    ret void
; CHECK:       loop:
; CHECK-NEXT:    [[IV:%.*]] = phi i64 [ [[IV_1:%.*]], [[LOOP]] ], [ 0, [[LOOP_PREHEADER]] ]
; CHECK-NEXT:    [[IDX:%.*]] = getelementptr inbounds i32, ptr [[PTR:%.*]], i64 [[IV]]
; CHECK-NEXT:    store i32 1, ptr [[IDX]], align 4
; CHECK-NEXT:    [[IV_1]] = add nuw nsw i64 [[IV]], 1
; CHECK-NEXT:    [[LOOP_COND:%.*]] = icmp eq i64 [[IV_1]], [[N_CAST]]
; CHECK-NEXT:    br i1 [[LOOP_COND]], label [[EXIT_LOOPEXIT:%.*]], label [[LOOP]]
;
  %n.cast = zext i32 %n to i64
  %len = shl nuw nsw i64 %n.cast, 2
  tail call void @llvm.memset.p0i8.i64(ptr align 4 %ptr, i8 0, i64 %len, i1 false)
  %entry.cond = icmp eq i32 %n, 0
  br i1 %entry.cond, label %exit, label %loop.preheader

loop.preheader:                                   ; preds = %entry
  br label %loop

exit.loopexit:                                    ; preds = %loop
  br label %exit

exit:                                             ; preds = %exit.loopexit, %entry
  ret void

loop:                                             ; preds = %loop.preheader, %loop
  %iv = phi i64 [ %iv.1, %loop ], [ 0, %loop.preheader ]
  %idx = getelementptr inbounds i32, ptr %ptr, i64 %iv
  store i32 1, ptr %idx, align 4
  %iv.1 = add nuw nsw i64 %iv, 1
  %loop.cond = icmp eq i64 %iv.1, %n.cast
  br i1 %loop.cond, label %exit.loopexit, label %loop
}

; Check if memory intrinsic in %entry is removed when store in %loop overwrites it completely, but
; the induction variable is decremented by moving from %n to 0
; TODO: We don't remove memset in %entry now
define void @decremented_indvar_and_memory_intrinsic(ptr nocapture %ptr, i32 %n) local_unnamed_addr #0 {
; CHECK-LABEL: @decremented_indvar_and_memory_intrinsic(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[N_CAST:%.*]] = zext i32 [[N:%.*]] to i64
; CHECK-NEXT:    [[LEN:%.*]] = shl nuw nsw i64 [[N_CAST]], 2
; CHECK-NEXT:    tail call void @llvm.memset.p0.i64(ptr align 4 [[PTR:%.*]], i8 0, i64 [[LEN]], i1 false)
; CHECK-NEXT:    br label [[HEADER:%.*]]
; CHECK:       header:
; CHECK-NEXT:    [[IV:%.*]] = phi i32 [ [[N]], [[ENTRY:%.*]] ], [ [[IV_1:%.*]], [[LATCH:%.*]] ]
; CHECK-NEXT:    [[IV_1]] = add i32 [[IV]], -1
; CHECK-NEXT:    [[HEADER_COND:%.*]] = icmp sgt i32 [[IV_1]], -1
; CHECK-NEXT:    br i1 [[HEADER_COND]], label [[LATCH]], label [[EXIT:%.*]]
; CHECK:       exit:
; CHECK-NEXT:    ret void
; CHECK:       latch:
; CHECK-NEXT:    [[IV_1_CAST:%.*]] = zext i32 [[IV_1]] to i64
; CHECK-NEXT:    [[IDX:%.*]] = getelementptr inbounds i32, ptr [[PTR]], i64 [[IV_1_CAST]]
; CHECK-NEXT:    store i32 1, ptr [[IDX]], align 4
; CHECK-NEXT:    br label [[HEADER]]
;
entry:
  %n.cast = zext i32 %n to i64
  %len = shl nuw nsw i64 %n.cast, 2
  tail call void @llvm.memset.p0i8.i64(ptr align 4 %ptr, i8 0, i64 %len, i1 false)
  br label %header

header:                                                ; preds = %latch, %entry
  %iv = phi i32 [ %n, %entry ], [ %iv.1, %latch ]
  %iv.1 = add i32 %iv, -1
  %header.cond = icmp sgt i32 %iv.1, -1
  br i1 %header.cond, label %latch, label %exit

exit:                                               ; preds = %header
  ret void

latch:                                               ; preds = %header
  %iv.1.cast = zext i32 %iv.1 to i64
  %idx = getelementptr inbounds i32, ptr %ptr, i64 %iv.1.cast
  store i32 1, ptr %idx, align 4
  br label %header
}

; Check if memory intrinsic in %entry is removed because its offset is different
; from what we have for store in %loop
; TODO: We don't account for different offset
define void @different_offsets(ptr nocapture %ptr.a, ptr nocapture %ptr.b, i32 %n) {
; CHECK-LABEL: @different_offsets(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[PTR_A_OFFSET:%.*]] = getelementptr i32, ptr [[PTR_A:%.*]], i32 4
; CHECK-NEXT:    [[PTR_A_CAST:%.*]] = bitcast ptr [[PTR_A_OFFSET]] to ptr
; CHECK-NEXT:    [[N_CAST:%.*]] = zext i32 [[N:%.*]] to i64
; CHECK-NEXT:    [[LEN:%.*]] = shl nsw i64 [[N_CAST]], 2
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr [[PTR_A_CAST]], i8 0, i64 [[N_CAST]], i1 false)
; CHECK-NEXT:    [[ENTRY_COND:%.*]] = icmp eq i64 [[N_CAST]], 0
; CHECK-NEXT:    br i1 [[ENTRY_COND]], label [[EXIT:%.*]], label [[LOOP:%.*]]
; CHECK:       exit:
; CHECK-NEXT:    ret void
; CHECK:       loop:
; CHECK-NEXT:    [[IV:%.*]] = phi i64 [ [[IV_2:%.*]], [[LOOP]] ], [ 0, [[ENTRY:%.*]] ]
; CHECK-NEXT:    [[IDX_A:%.*]] = getelementptr inbounds i32, ptr [[PTR_A]], i64 [[IV]]
; CHECK-NEXT:    [[TMP:%.*]] = load i32, ptr [[IDX_A]], align 4
; CHECK-NEXT:    [[IDX_B:%.*]] = getelementptr inbounds i32, ptr [[PTR_B:%.*]], i64 [[IV]]
; CHECK-NEXT:    store i32 [[TMP]], ptr [[IDX_B]], align 4
; CHECK-NEXT:    store i32 1, ptr [[IDX_A]], align 4
; CHECK-NEXT:    [[IV_2]] = add nuw nsw i64 [[N_CAST]], 2
; CHECK-NEXT:    [[LOOP_COND:%.*]] = icmp eq i64 [[IV_2]], [[N_CAST]]
; CHECK-NEXT:    br i1 [[LOOP_COND]], label [[EXIT]], label [[LOOP]]
;
entry:
  %ptr.a.offset = getelementptr i32, ptr %ptr.a, i32 4
  %ptr.a.cast = bitcast ptr %ptr.a.offset to ptr
  %n.cast = zext i32 %n to i64
  %len = shl nsw i64 %n.cast, 2
  call void @llvm.memset.p0i8.i64(ptr %ptr.a.cast, i8 0, i64 %n.cast, i1 false)
  %entry.cond = icmp eq i64 %n.cast, 0
  br i1 %entry.cond, label %exit, label %loop
exit:
  ret void

loop:
  %iv = phi i64 [ %iv.2, %loop ], [ 0, %entry ]
  %idx.a = getelementptr inbounds i32, ptr %ptr.a, i64 %iv
  %tmp = load i32, ptr %idx.a
  %idx.b = getelementptr inbounds i32, ptr %ptr.b, i64 %iv
  store i32 %tmp, ptr %idx.b
  store i32 1, ptr %idx.a
  %iv.2 = add nuw nsw i64 %n.cast, 2
  %loop.cond = icmp eq i64 %iv.2, %n.cast
  br i1 %loop.cond, label %exit, label %loop
}

; It checks if memory intrinsic is not removed when there is a path on which
; we don't store anything and on another one we have a store so this intrinsic is not redundant
define void @on_overwrite_in_loop(ptr nocapture %ptr, i32 %n, i1 zeroext %x) {
; CHECK-LABEL: @on_overwrite_in_loop(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[N_SEXT:%.*]] = sext i32 [[N:%.*]] to i64
; CHECK-NEXT:    [[LEN:%.*]] = shl nsw i64 [[N_SEXT]], 2
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[PTR:%.*]], i8 0, i64 [[LEN]], i1 false)
; CHECK-NEXT:    [[ENTRY_COND:%.*]] = icmp sgt i32 [[N]], 0
; CHECK-NEXT:    br i1 [[ENTRY_COND]], label [[PREHEADER:%.*]], label [[EXIT:%.*]]
; CHECK:       preheader:
; CHECK-NEXT:    [[N_ZEXT:%.*]] = zext i32 [[N]] to i64
; CHECK-NEXT:    br label [[HEADER:%.*]]
; CHECK:       exit:
; CHECK-NEXT:    ret void
; CHECK:       header:
; CHECK-NEXT:    [[IV:%.*]] = phi i64 [ 0, [[PREHEADER]] ], [ [[IV_1:%.*]], [[LATCH:%.*]] ]
; CHECK-NEXT:    br i1 [[X:%.*]], label [[DUMMY_BLOCK:%.*]], label [[STORE_BLOCK:%.*]]
; CHECK:       dummy.block:
; CHECK-NEXT:    call void @dummy()
; CHECK-NEXT:    br label [[LATCH]]
; CHECK:       store.block:
; CHECK-NEXT:    [[IDX:%.*]] = getelementptr inbounds i32, ptr [[PTR]], i64 [[IV]]
; CHECK-NEXT:    store i32 1, ptr [[IDX]], align 4
; CHECK-NEXT:    br label [[LATCH]]
; CHECK:       latch:
; CHECK-NEXT:    [[IV_1]] = add nuw nsw i64 [[IV]], 1
; CHECK-NEXT:    [[LATCH_COND:%.*]] = icmp eq i64 [[IV_1]], [[N_ZEXT]]
; CHECK-NEXT:    br i1 [[LATCH_COND]], label [[EXIT]], label [[HEADER]]
;
entry:
  %n.sext = sext i32 %n to i64
  %len = shl nsw i64 %n.sext, 2
  call void @llvm.memset.p0i8.i64(ptr align 4 %ptr, i8 0, i64 %len, i1 false)
  %entry.cond = icmp sgt i32 %n, 0
  br i1 %entry.cond, label %preheader, label %exit

preheader:                                                ; preds = %entry
  %n.zext = zext i32 %n to i64
  br label %header

exit:                                               ; preds = %latch, %entry
  ret void

header:                                               ; preds = %preheader, %latch
  %iv = phi i64 [ 0, %preheader ], [ %iv.1, %latch ]
  br i1 %x, label %dummy.block, label %store.block

dummy.block:                                               ; preds = %header
  call void @dummy()
  br label %latch

store.block:                                               ; preds = %header
  %idx = getelementptr inbounds i32, ptr %ptr, i64 %iv
  store i32 1, ptr %idx, align 4
  br label %latch

latch:                                               ; preds = %dummy.block, %store.block
  %iv.1 = add nuw nsw i64 %iv, 1
  %latch.cond = icmp eq i64 %iv.1, %n.zext
  br i1 %latch.cond, label %exit, label %header
}

define void @constant_length(ptr nocapture %ptr) {
; CHECK-LABEL: @constant_length(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    br label [[LOOP:%.*]]
; CHECK:       exit:
; CHECK-NEXT:    ret void
; CHECK:       loop:
; CHECK-NEXT:    [[IV:%.*]] = phi i64 [ 0, [[ENTRY:%.*]] ], [ [[IV_1:%.*]], [[LOOP]] ]
; CHECK-NEXT:    [[IDX:%.*]] = getelementptr inbounds i32, ptr [[PTR:%.*]], i64 [[IV]]
; CHECK-NEXT:    store i32 1, ptr [[IDX]], align 4
; CHECK-NEXT:    [[IV_1]] = add nuw nsw i64 [[IV]], 1
; CHECK-NEXT:    [[LOOP_COND:%.*]] = icmp eq i64 [[IV_1]], 128
; CHECK-NEXT:    br i1 [[LOOP_COND]], label [[EXIT:%.*]], label [[LOOP]]
;
entry:
  call void @llvm.memset.p0i8.i64(ptr noundef nonnull align 4 dereferenceable(512) %ptr, i8 0, i64 512, i1 false)
  br label %loop

exit:                                                ; preds = %loop
  ret void

loop:                                                ; preds = %entry, %loop
  %iv = phi i64 [ 0, %entry ], [ %iv.1, %loop ]
  %idx = getelementptr inbounds i32, ptr %ptr, i64 %iv
  store i32 1, ptr %idx, align 4
  %iv.1 = add nuw nsw i64 %iv, 1
  %loop.cond = icmp eq i64 %iv.1, 128
  br i1 %loop.cond, label %exit, label %loop
}

declare void @dummy()
declare i32 @llvm.smax.i32(i32, i32)
declare void @llvm.memset.p0i8.i64(ptr nocapture writeonly, i8, i64, i1 immarg)
declare void @llvm.memcpy.p0i8.p0i8.i64(ptr, ptr, i64, i1)
